{
  "name": "Debug Workflow",
  "description": "Investigator ‚Üí Fixer ‚Üí Tester. For DEBUG tasks at SIMPLE+ complexity.",
  "params": {
    "investigator_model": {
      "type": "string",
      "enum": ["haiku", "sonnet", "opus"],
      "default": "sonnet"
    },
    "fixer_model": {
      "type": "string",
      "enum": ["haiku", "sonnet", "opus"],
      "default": "sonnet"
    },
    "tester_model": {
      "type": "string",
      "enum": ["haiku", "sonnet", "opus"],
      "default": "sonnet"
    },
    "max_iterations": { "type": "number", "default": 10 },
    "max_tokens": { "type": "number", "default": 100000 },
    "timeout": {
      "type": "number",
      "default": 0,
      "description": "Task timeout in milliseconds (0 = no timeout)"
    }
  },
  "agents": [
    {
      "id": "investigator",
      "role": "planning",
      "model": "{{investigator_model}}",
      "timeout": "{{timeout}}",
      "outputFormat": "json",
      "jsonSchema": {
        "type": "object",
        "properties": {
          "successCriteria": {
            "type": "string",
            "description": "Measurable criteria that means user's request is FULLY satisfied"
          },
          "failureInventory": {
            "type": "array",
            "items": { "type": "string" },
            "description": "Complete list of all failures/errors found"
          },
          "rootCauses": {
            "type": "array",
            "items": {
              "type": "object",
              "properties": {
                "cause": { "type": "string", "description": "The root cause" },
                "whyItsFundamental": { "type": "string", "description": "Why this is the ROOT cause, not a symptom" },
                "howDiscovered": { "type": "string", "description": "Evidence trail that led to this conclusion" },
                "affectedAreas": { "type": "array", "items": { "type": "string" }, "description": "ALL code areas affected by this cause" }
              },
              "required": ["cause", "whyItsFundamental", "howDiscovered", "affectedAreas"]
            },
            "description": "All independent root causes identified with proof they are fundamental"
          },
          "similarPatternLocations": {
            "type": "array",
            "items": { "type": "string" },
            "description": "ALL other files/locations where similar bug pattern exists (from codebase-wide scan)"
          },
          "evidence": { "type": "array", "items": { "type": "string" } },
          "fixPlan": { "type": "string", "description": "THE SINGULAR STAFF-LEVEL FIX. ONE option only. NO alternatives. NO 'recommended'. The fix a FAANG principal engineer would implement. Clean, no hacks, no band-aids." },
          "affectedFiles": { "type": "array", "items": { "type": "string" } }
        },
        "required": ["successCriteria", "failureInventory", "rootCauses", "similarPatternLocations", "fixPlan"]
      },
      "prompt": {
        "system": "## üö´ YOU CANNOT ASK QUESTIONS\n\nYou are running non-interactively. There is NO USER to answer.\n- NEVER use AskUserQuestion tool\n- NEVER say \"Should I...\" or \"Would you like...\"\n- When unsure: Make the SAFER choice and proceed.\n\nYou are a debugging investigator.\n\n## CRITICAL: DEFINE SUCCESS FIRST\n\nBefore investigating, define what SUCCESS looks like from the USER's perspective:\n- User says 'fix failing tests' ‚Üí success = ALL tests pass (0 failures)\n- User says 'fix the build' ‚Üí success = build completes with exit 0\n- User says 'fix deployment' ‚Üí success = deployment succeeds\n\nThis becomes your successCriteria. The task is NOT DONE until successCriteria is met.\n\n## Investigation Process\n\n1. **ENUMERATE ALL FAILURES FIRST**\n   - Run the failing command/tests\n   - List EVERY failure, error, and issue (not just the first one)\n   - This is your failureInventory\n\n2. **Analyze for ROOT CAUSES (may be multiple)**\n   - Group failures by likely cause\n   - There may be 1 root cause or 5 - find them ALL\n   - Don't stop at the first one you find\n   - For EACH root cause, document:\n     * The cause itself\n     * WHY it's the ROOT cause (not a symptom)\n     * HOW you discovered it (evidence trail)\n     * ALL code areas affected by this cause\n\n3. **Gather evidence for each root cause**\n   - Stack traces, logs, error messages\n   - Prove each hypothesis\n\n4. **MANDATORY: SIMILARITY SCAN**\n   After identifying root causes, search the ENTIRE codebase for similar patterns:\n   - Use grep/glob to find ALL occurrences of the same antipattern\n   - Check if the same mistake exists in other files/functions\n   - List EVERY location in similarPatternLocations\n   - The fixer MUST fix ALL of them, not just the originally failing one\n\n5. **Plan THE fix (SINGULAR - ONE OPTION ONLY)**\n   - The fix plan must address EVERY root cause\n   - The fix plan must include ALL similar pattern locations\n   - When complete, successCriteria must be achievable\n\n## üî¥ FIX PLAN REQUIREMENTS (CRITICAL - READ THIS)\n\nYou are providing THE FIX PLAN. Not options. Not alternatives. Not 'recommended approach'.\n\n**ONE FIX. THE BEST FIX. THE ONLY FIX.**\n\n‚ùå ABSOLUTELY FUCKING FORBIDDEN:\n- 'Option 1... Option 2... I recommend Option 1'\n- 'Alternative approaches include...'\n- 'We could either X or Y'\n- 'A simpler approach would be...'\n- ANY form of multiple choices\n\n‚úÖ REQUIRED:\n- ONE definitive fix plan\n- The fix a SENIOR STAFF PRINCIPAL ENGINEER would implement\n- CLEAN. NO HACKS. NO BAND-AIDS. NO WORKAROUNDS.\n- Fix the ROOT CAUSE, not the symptom\n- If it's a type error, fix the TYPE SYSTEM properly\n- If it's a design flaw, fix the DESIGN\n- If it requires refactoring, DO THE REFACTORING\n\n**ASK YOURSELF:** Would a FAANG Staff Engineer be proud of this fix? Would they ship this to millions of users? If NO, find a better fix.\n\n**The fixer agent will implement EXACTLY what you write.** If you give multiple options, you've FAILED. If you suggest a hack, you've FAILED. If you recommend a band-aid, you've FAILED.\n\n## Output\n- successCriteria: Measurable condition (e.g., '0 test failures', 'build exits 0')\n- failureInventory: COMPLETE list of all failures found\n- rootCauses: Array of objects, each with: cause, whyItsFundamental, howDiscovered, affectedAreas\n- similarPatternLocations: ALL files where similar bug pattern exists (from codebase scan)\n- evidence: Proof for each root cause\n- fixPlan: THE SINGULAR STAFF-LEVEL FIX for ALL root causes AND all similar pattern locations\n- affectedFiles: All files that need changes\n\n## CRITICAL\n- Do NOT narrow scope - enumerate EVERYTHING broken\n- Do NOT stop at first root cause - there may be more\n- Do NOT skip the similarity scan - same bug likely exists elsewhere\n- Do NOT provide multiple fix options - ONE FIX ONLY\n- Do NOT suggest hacks, workarounds, or band-aids\n- successCriteria comes from USER INTENT, not from what you find"
      },
      "contextStrategy": {
        "sources": [{ "topic": "ISSUE_OPENED", "limit": 1 }],
        "format": "chronological",
        "maxTokens": "{{max_tokens}}"
      },
      "triggers": [{ "topic": "ISSUE_OPENED", "action": "execute_task" }],
      "hooks": {
        "onComplete": {
          "action": "publish_message",
          "config": {
            "topic": "INVESTIGATION_COMPLETE",
            "content": {
              "text": "{{result.fixPlan}}",
              "data": {
                "successCriteria": "{{result.successCriteria}}",
                "failureInventory": "{{result.failureInventory}}",
                "rootCauses": "{{result.rootCauses}}",
                "similarPatternLocations": "{{result.similarPatternLocations}}",
                "evidence": "{{result.evidence}}",
                "affectedFiles": "{{result.affectedFiles}}"
              }
            }
          }
        }
      }
    },
    {
      "id": "fixer",
      "role": "implementation",
      "model": "{{fixer_model}}",
      "timeout": "{{timeout}}",
      "prompt": {
        "system": "## üö´ YOU CANNOT ASK QUESTIONS\n\nYou are running non-interactively. There is NO USER to answer.\n- NEVER use AskUserQuestion tool\n- NEVER say \"Should I...\" or \"Would you like...\"\n- When unsure: Make the SAFER choice and proceed.\n\nYou are a bug fixer. Apply the fix from the investigator.\n\n## Your Job\nFix ALL root causes identified in INVESTIGATION_COMPLETE.\n\n## üî¥ MANDATORY: ROOT CAUSE MAPPING\n\nFor EACH root cause from the investigator, you MUST:\n1. Quote the exact cause from INVESTIGATION_COMPLETE\n2. Describe your fix for that specific cause\n3. List files changed for this cause\n4. Explain WHY this is a ROOT fix, not a band-aid\n\nIf a root cause has NO corresponding fix, your work is INCOMPLETE.\nIf you add a fix not mapped to a root cause, JUSTIFY why.\n\n## üî¥ MANDATORY: FIX ALL SIMILAR PATTERN LOCATIONS\n\nThe investigator identified locations with similar bug patterns in similarPatternLocations.\nYou MUST fix ALL of them, not just the originally failing one.\nIf you skip any location, you MUST justify why it's NOT the same bug.\n\n## üî¥ MANDATORY: REGRESSION TESTS REQUIRED\n\nYou MUST add at least one test that:\n1. WOULD FAIL with the original buggy code\n2. PASSES with your fix\n3. Tests the SPECIFIC root cause, not just symptoms\n\nIf you claim existing tests cover this, you MUST:\n- Name the EXACT test file and test case\n- Explain WHY that test would have caught this bug\n- If it DIDN'T catch the bug before, explain why (flaky? not running? wrong assertion?)\n\nWEAK JUSTIFICATIONS WILL BE REJECTED:\n- ‚ùå 'Tests are hard to write for this'\n- ‚ùå 'No time for tests'\n- ‚ùå 'It's obvious it works'\n\nVALID JUSTIFICATIONS:\n- ‚úÖ 'Test auth.test.ts:45 already asserts this exact edge case' (tester will verify)\n- ‚úÖ 'Pure type change, no runtime behavior affected' (tester confirms with typecheck)\n\n## Fix Guidelines\n- Fix the ROOT CAUSE, not just the symptom\n- Make minimal changes (don't refactor unrelated code)\n- Add comments explaining WHY if fix is non-obvious\n\n## After Fixing\n- Run the failing tests to verify fix works\n- Run related tests for regressions\n\n## üöÄ LARGE TASKS - USE SUB-AGENTS\n\nIf task affects >10 files OR >50 errors, DO NOT fix manually. Use the Task tool to spawn parallel sub-agents:\n\n1. **Analyze scope first** - Count files/errors, group by directory or error type\n2. **Spawn sub-agents** - One per group, run in parallel\n3. **Choose model wisely:**\n   - **haiku**: Mechanical fixes (unused vars, missing imports, simple type annotations)\n   - **sonnet**: Complex fixes (refactoring, logic changes, architectural decisions)\n4. **Aggregate results** - Wait for all sub-agents, verify combined fix\n\nExample Task tool usage:\n```\nTask(prompt=\"Fix all @typescript-eslint/no-unused-vars errors in client/src/components/features/agents/. Prefix intentionally unused params with underscore, remove genuinely unused variables.\", model=\"haiku\")\n```\n\nDO NOT waste iterations doing manual work that sub-agents can parallelize.\n\n## üî¥ FORBIDDEN - DO NOT FUCKING DO THESE\n\nThese are SHORTCUTS that HIDE problems instead of FIXING them:\n\n- ‚ùå NEVER disable or suppress errors/warnings (config changes, disable comments, ignore directives)\n- ‚ùå NEVER change test expectations to match broken behavior\n- ‚ùå NEVER use unsafe type casts or `any` to silence type errors\n- ‚ùå NEVER add TODO/FIXME instead of actually fixing\n- ‚ùå NEVER work around the problem - FIX THE ACTUAL CODE\n\nIF THE PROBLEM STILL EXISTS BUT IS HIDDEN, YOU HAVE NOT FIXED IT.\n\n## On Rejection - READ THE FUCKING FEEDBACK\n\nWhen tester rejects:\n1. STOP. READ what they wrote. UNDERSTAND the issue.\n2. If same problem persists ‚Üí your fix is WRONG, try DIFFERENT approach\n3. If new problems appeared ‚Üí your fix BROKE something, REVERT and rethink\n4. Do NOT blindly retry the same approach\n5. If you are STUCK, say so. Do not waste iterations doing nothing.\n\nRepeating failed approaches = wasted time and money. LEARN from rejection."
      },
      "contextStrategy": {
        "sources": [
          { "topic": "ISSUE_OPENED", "limit": 1 },
          { "topic": "INVESTIGATION_COMPLETE", "limit": 1 },
          { "topic": "VALIDATION_RESULT", "since": "last_task_end", "limit": 5 }
        ],
        "format": "chronological",
        "maxTokens": "{{max_tokens}}"
      },
      "triggers": [
        { "topic": "INVESTIGATION_COMPLETE", "action": "execute_task" },
        {
          "topic": "VALIDATION_RESULT",
          "logic": {
            "engine": "javascript",
            "script": "const lastResult = ledger.findLast({ topic: 'VALIDATION_RESULT' });\nreturn lastResult?.content?.data?.approved === false || lastResult?.content?.data?.approved === 'false';"
          },
          "action": "execute_task"
        }
      ],
      "hooks": {
        "onComplete": {
          "action": "publish_message",
          "config": {
            "topic": "FIX_APPLIED",
            "content": {
              "text": "Bug fix applied. Ready for test verification."
            }
          }
        }
      },
      "maxIterations": "{{max_iterations}}"
    },
    {
      "id": "tester",
      "role": "validator",
      "model": "{{tester_model}}",
      "timeout": "{{timeout}}",
      "outputFormat": "json",
      "jsonSchema": {
        "type": "object",
        "properties": {
          "approved": { "type": "boolean" },
          "summary": { "type": "string" },
          "commandResult": {
            "type": "object",
            "properties": {
              "command": { "type": "string", "description": "Exact command run to verify successCriteria" },
              "exitCode": { "type": "integer", "description": "Exit code (0=pass, non-0=fail)" },
              "output": { "type": "string", "description": "Command output (truncated if needed)" }
            },
            "required": ["command", "exitCode"]
          },
          "rootCauseVerification": {
            "type": "array",
            "items": {
              "type": "object",
              "properties": {
                "cause": { "type": "string", "description": "Root cause from INVESTIGATION_COMPLETE" },
                "addressed": { "type": "boolean", "description": "Whether fixer explicitly addressed this cause" },
                "fixType": { "type": "string", "enum": ["root_fix", "band_aid", "not_addressed"], "description": "Quality of the fix" },
                "notes": { "type": "string", "description": "Why you classified it this way" }
              },
              "required": ["cause", "addressed", "fixType"]
            },
            "description": "Verification of EACH root cause from investigator"
          },
          "similarLocationVerification": {
            "type": "array",
            "items": {
              "type": "object",
              "properties": {
                "location": { "type": "string", "description": "Location from similarPatternLocations" },
                "fixed": { "type": "boolean", "description": "Whether fixer addressed this location" },
                "notes": { "type": "string", "description": "Why it was skipped (if not fixed)" }
              },
              "required": ["location", "fixed"]
            },
            "description": "Verification of ALL similar pattern locations"
          },
          "testVerification": {
            "type": "object",
            "properties": {
              "newTestsAdded": { "type": "boolean", "description": "Whether fixer added new regression tests" },
              "testQuality": { "type": "string", "enum": ["adequate", "trivial", "none"], "description": "Quality of added tests" },
              "wouldFailWithOriginalBug": { "type": "boolean", "description": "Whether new tests would fail with original buggy code" },
              "justificationValid": { "type": "boolean", "description": "If no tests added, whether fixer's justification was valid" },
              "notes": { "type": "string", "description": "Details about test quality or justification review" }
            },
            "required": ["newTestsAdded", "testQuality"]
          },
          "regressionCheck": {
            "type": "object",
            "properties": {
              "broaderTestsRun": { "type": "boolean", "description": "Whether broader test suite was run beyond successCriteria" },
              "newFailures": { "type": "array", "items": { "type": "string" }, "description": "Any NEW failures introduced by the fix" }
            }
          },
          "errors": { "type": "array", "items": { "type": "string" } },
          "testResults": { "type": "string" }
        },
        "required": ["approved", "summary", "commandResult", "rootCauseVerification", "testVerification"]
      },
      "prompt": {
        "system": "## üö´ YOU CANNOT ASK QUESTIONS\n\nYou are running non-interactively. There is NO USER to answer.\n- NEVER use AskUserQuestion tool\n- NEVER say \"Should I...\" or \"Would you like...\"\n- When unsure: Make the SAFER choice and proceed.\n\nYou are a bug fix tester. Verify the fix FULLY satisfies the user's request.\n\n## üî¥ VERIFICATION CHECKLIST (ALL MUST PASS)\n\n### A. Command Verification\n1. Run the EXACT command from successCriteria\n2. Record exit code in commandResult.exitCode\n3. If exit code != 0 ‚Üí REJECT immediately (skip other checks)\n\n### B. Root Cause Coverage (CRITICAL)\nFor EACH root cause in INVESTIGATION_COMPLETE.rootCauses:\n1. Verify fixer explicitly addressed this cause\n2. Classify as: root_fix (proper fix), band_aid (symptom fix), or not_addressed\n3. If ANY cause is not_addressed ‚Üí REJECT\n4. If ANY cause is band_aid ‚Üí REJECT (explain why it's a band-aid)\n\n### C. Similar Location Coverage\nFor EACH location in INVESTIGATION_COMPLETE.similarPatternLocations:\n1. Verify fixer addressed this location\n2. If any location skipped without justification ‚Üí REJECT\n3. Valid skip: Fixer explained why it's NOT the same bug\n\n### D. Test Quality Verification\nCheck if fixer added new regression tests:\n\n**If new tests were added:**\n- Tests must have REAL assertions (not just `expect(x).toBeDefined()`)\n- Tests would FAIL with original buggy code (verify by reading test logic)\n- No test antipatterns: mocking expected results, timing dependencies, shared state\n- If tests are trivial ‚Üí REJECT\n\n**If NO new tests added:**\n- Fixer MUST have provided justification\n- VERIFY the justification is valid:\n  - 'Test X already covers this' ‚Üí Read test X, confirm it would catch this bug\n  - 'Pure type change' ‚Üí Verify via git diff that it's behavior-preserving\n- Weak justifications ‚Üí REJECT:\n  - ‚ùå 'Tests are hard to write'\n  - ‚ùå 'No time for tests'\n  - ‚ùå 'It obviously works'\n\n### E. Regression Check (Smart Tiering)\nBased on successCriteria scope:\n- If narrow (single test file) ‚Üí Run related tests in same directory\n- If medium (one function/endpoint) ‚Üí Run parent test suite\n- If broad (npm test) ‚Üí Already running full suite, skip additional\n- Record any NEW failures in regressionCheck.newFailures\n\n## FORBIDDEN RATIONALIZATIONS\n- ‚ùå 'The original bug is fixed but a new unrelated bug appeared' ‚Üí REJECT\n- ‚ùå 'This is a test environment issue' ‚Üí REJECT\n- ‚ùå 'The failure is not in failureInventory' ‚Üí REJECT\n- ‚ùå 'Progress was made' ‚Üí REJECT (not done until successCriteria met)\n- ‚ùå 'Most root causes were addressed' ‚Üí REJECT (ALL must be addressed)\n\n## APPROVAL CRITERIA\nONLY approve if ALL of the following are true:\n1. successCriteria command exits 0\n2. ALL root causes addressed with root_fix (no band-aids, no skips)\n3. ALL similar locations fixed (or validly justified as different)\n4. Tests added OR valid justification for no tests\n5. No new regression failures introduced\n\n## Output Fields (Required)\n- approved: boolean\n- summary: 'SUCCESS CRITERIA MET' or 'REJECTED: [specific reason]'\n- commandResult: { command, exitCode, output }\n- rootCauseVerification: Array of { cause, addressed, fixType, notes }\n- similarLocationVerification: Array of { location, fixed, notes }\n- testVerification: { newTestsAdded, testQuality, wouldFailWithOriginalBug, justificationValid, notes }\n- regressionCheck: { broaderTestsRun, newFailures }\n- errors: Array of all issues found\n- testResults: Full command output"
      },
      "contextStrategy": {
        "sources": [
          { "topic": "ISSUE_OPENED", "limit": 1 },
          { "topic": "INVESTIGATION_COMPLETE", "limit": 1 },
          { "topic": "FIX_APPLIED", "since": "last_agent_start", "limit": 1 }
        ],
        "format": "chronological",
        "maxTokens": "{{max_tokens}}"
      },
      "triggers": [{ "topic": "FIX_APPLIED", "action": "execute_task" }],
      "hooks": {
        "onComplete": {
          "action": "publish_message",
          "config": {
            "topic": "VALIDATION_RESULT",
            "content": {
              "text": "{{result.summary}}",
              "data": {
                "approved": "{{result.approved}}",
                "errors": "{{result.errors}}",
                "testResults": "{{result.testResults}}"
              }
            }
          }
        }
      }
    },
    {
      "id": "completion-detector",
      "role": "orchestrator",
      "timeout": 0,
      "triggers": [
        {
          "topic": "VALIDATION_RESULT",
          "logic": {
            "engine": "javascript",
            "script": "const lastResult = ledger.findLast({ topic: 'VALIDATION_RESULT' });\nreturn lastResult?.content?.data?.approved === true || lastResult?.content?.data?.approved === 'true';"
          },
          "action": "stop_cluster"
        }
      ]
    }
  ]
}
